{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "source": [
    "# Pipeline to perform t-test on performances different combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "CiDn2Sk-VWqE",
    "outputId": "64224cd2-6054-4b04-a3f6-af8290400dfc"
   },
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git\n",
    "#!pip install sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data module\n",
    "from adni.load_data import load_data\n",
    "\n",
    "# Import needed modules\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NE_fTbKGe5z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples: 855\n",
      "The number of columns: 268\n"
     ]
    }
   ],
   "source": [
    "# Data loading \n",
    "data = load_data()\n",
    "print(f'The number of samples: {len(data.index)}')\n",
    "print(f'The number of columns: {len(data.columns)}')\n",
    "df= pd.DataFrame(data)\n",
    "\n",
    "# Reset index, add patient ID's as column\n",
    "df.reset_index(inplace=True)\n",
    "df = df.rename(columns = {'index':'ID'})\n",
    "\n",
    "# Set AD to 1, CN to 0\n",
    "df['label']= df['label'].replace(['AD'],1) \n",
    "df['label']= df['label'].replace(['CN'],0) \n",
    "\n",
    "# set seed\n",
    "\n",
    "# display data frame\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples after cleaning + std: 855\n",
      "The number of columns after cleaning + std: 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wt/6j07594j3bs65w_hh8gnyk4r0000gn/T/ipykernel_64586/747128131.py:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_new = df.drop(df.std()[df.std() == 0].index.values, axis = 1)\n"
     ]
    }
   ],
   "source": [
    "# Check wheter there is missing data (NaN)\n",
    "df.notnull().values.any() # Geen missing data\n",
    "\n",
    "# Als SD 0 dan feature weggooien\n",
    "df_new = df.drop(df.std()[df.std() == 0].index.values, axis = 1)\n",
    "\n",
    "print(f'The number of samples after cleaning + std: {len(df_new.index)}')\n",
    "print(f'The number of columns after cleaning + std: {len(df_new.columns)}')\n",
    "\n",
    "# Count number of duplicated patiient ID's\n",
    "df.index.duplicated().sum() # ID's are indices in df\n",
    "X = df.drop('ID', axis=1) # Drop patient ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split in test, train and validation set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in test-set & train/validation-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test / Train split: stratified op label --> nagaan of we dit ook willen\n",
    "y = df['label'] # Define label y (output)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, stratify = X['label'])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, stratify = X_train['label'])\n",
    "\n",
    "# Test of het gelukt is \n",
    "# print(len(X_train))\n",
    "# print(len(X_test))\n",
    "# print(sum(X_test['label']=='AD'))\n",
    "# print(sum(X_train['label']=='AD'))\n",
    "\n",
    "# Drop labels and drop patient ID\n",
    "X_train = X_train.drop('label', axis=1)\n",
    "X_val = X_val.drop('label', axis=1)\n",
    "X_test = X_test.drop('label', axis=1)\n",
    "X = X.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline PCA + KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scaler\n",
    "2. Feature extraction: PCA\n",
    "3. Classifier: KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.791):\n",
      "{'pca__n_components': 60}\n",
      "0.7829457364341085\n",
      "0.8589743589743589\n",
      "0.7976190476190477\n",
      "0.762820512820513\n"
     ]
    }
   ],
   "source": [
    "# Define steps in pipeline\n",
    "pca = PCA()\n",
    "knn = KNeighborsClassifier()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create pipeline with steps: scaler, PCA, classifier\n",
    "pipe = Pipeline([('scaler', scaler), ('pca', pca), ('knn', knn)])\n",
    "\n",
    "# Define parameters for gridsearch: depending on which classifier\n",
    "param_grid = {\n",
    "    \"pca__n_components\": [5, 15, 30, 45, 60],\n",
    "    \n",
    "}\n",
    "# Perform Grid Search on pipe\n",
    "search = RandomizedSearchCV(pipe, param_grid, n_iter = 20, cv = 5)\n",
    "#search = GridSearchCV(pipe, param_grid, n_jobs=2)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print outcome Grid Search\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "best_params = search.best_params_\n",
    "print(best_params) \n",
    "\n",
    "pipe_after_grid = Pipeline([('scaler', scaler), ('pca', PCA((best_params['pca__n_components']))), ('knn', knn)])\n",
    "\n",
    "# Fit pipe_after_grid on data\n",
    "bst = pipe_after_grid.fit(X_train, y_train)\n",
    "\n",
    "#TEST PERFORMANCE\n",
    "y_pred = bst.predict(X_val)\n",
    "y_val = (np.array(y_val))\n",
    "\n",
    "print(bst.score(X_val, y_val))\n",
    "print(recall_score(y_val, y_pred))\n",
    "print(precision_score(y_val, y_pred))\n",
    "print(roc_auc_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline LDA + KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scaler\n",
    "2. Feature extraction: LDA\n",
    "3. Classifier: KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7596899224806202\n",
      "0.782051282051282\n",
      "0.8133333333333334\n",
      "0.7537707390648567\n"
     ]
    }
   ],
   "source": [
    "# Define steps in pipeline\n",
    "lda = LDA()\n",
    "knn = KNeighborsClassifier() \n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create pipeline with steps: scaler, PCA, classifier\n",
    "pipe = Pipeline([('scaler', scaler), ('lda', lda), ('knn', knn)])\n",
    "\n",
    "# Define parameters for gridsearch: depending on which classifier\n",
    "# param_grid = {\n",
    "    \n",
    "# }\n",
    "# # Perform Grid Search on pipe\n",
    "# search = RandomizedSearchCV(pipe, param_grid, n_iter = 20, cv = 5,\n",
    "# scoring = 'roc_auc')\n",
    "# search.fit(X_train, y_train)\n",
    "\n",
    "# # Print outcome Grid Search\n",
    "# print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "# best_params = search.best_params_\n",
    "# print(best_params) \n",
    "\n",
    "# pipe_after_grid = Pipeline([('scaler', scaler), ('lda', lda), ('svc', svc)])\n",
    "\n",
    "# Fit pipe_after_grid on data\n",
    "bst = pipe.fit(X_train, y_train)\n",
    "\n",
    "#TEST PERFORMANCE\n",
    "y_pred = bst.predict(X_val)\n",
    "y_val = (np.array(y_val))\n",
    "\n",
    "print(bst.score(X_val, y_val))\n",
    "print(recall_score(y_val, y_pred))\n",
    "print(precision_score(y_val, y_pred))\n",
    "print(roc_auc_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline kernel-PCA + KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scaler\n",
    "2. Feature extraction: kernel-PCA\n",
    "3. Classifier: KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.797):\n",
      "{'kpca__n_components': 60, 'kpca__kernel': 'cosine'}\n",
      "<bound method BaseEstimator._get_param_names of <class 'sklearn.model_selection._search.RandomizedSearchCV'>>\n",
      "0.7829457364341085\n",
      "0.8589743589743589\n",
      "0.7976190476190477\n",
      "0.762820512820513\n"
     ]
    }
   ],
   "source": [
    "# Define steps in pipeline\n",
    "kpca = KernelPCA()\n",
    "knn = KNeighborsClassifier()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create pipeline with steps: scaler, PCA, classifier\n",
    "pipe = Pipeline([('scaler', scaler), ('kpca', kpca), ('knn', knn)])\n",
    "\n",
    "# Define parameters for gridsearch: depending on which classifier\n",
    "param_grid = {\n",
    "    \"kpca__n_components\": [5, 15, 30, 45, 60],\n",
    "    \"kpca__kernel\": ['linear', 'poly', 'rbf', 'sigmoid', 'cosine'],\n",
    "}\n",
    "# Perform Grid Search on pipe\n",
    "search = RandomizedSearchCV(pipe, param_grid, n_iter = 20, cv = 5)\n",
    "#scoring = 'roc_auc')\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print outcome Grid Search\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "best_params = search.best_params_\n",
    "print(best_params) \n",
    "print(search._get_param_names)\n",
    "pipe_after_grid = Pipeline([('scaler', scaler), ('kpca', KernelPCA((best_params['kpca__n_components']))), ('knn', knn)])\n",
    "\n",
    "# Fit pipe_after_grid on data\n",
    "bst = pipe_after_grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#TEST PERFORMANCE\n",
    "y_pred = bst.predict(X_val)\n",
    "y_val = (np.array(y_val))\n",
    "\n",
    "print(bst.score(X_val, y_val))\n",
    "print(recall_score(y_val, y_pred))\n",
    "print(precision_score(y_val, y_pred))\n",
    "print(roc_auc_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline PCA + RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scaler\n",
    "2. Feature extraction: PCA\n",
    "3. Classifier: RF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.801):\n",
      "{'pca__n_components': 60}\n",
      "0.7906976744186046\n",
      "0.8717948717948718\n",
      "0.8\n",
      "0.7692307692307694\n"
     ]
    }
   ],
   "source": [
    "# Define steps in pipeline\n",
    "scaler = StandardScaler()\n",
    "pca = PCA()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Create pipeline with steps: scaler, PCA, classifier\n",
    "pipe = Pipeline([('scaler', scaler), ('pca', pca), ('rf', rf)])\n",
    "\n",
    "# Define parameters for gridsearch: depending on which classifier\n",
    "param_grid = {\n",
    "    \"pca__n_components\": [5, 15, 30, 45, 60],\n",
    "    \n",
    "}\n",
    "# Perform Grid Search on pipe\n",
    "search = RandomizedSearchCV(pipe, param_grid, n_iter = 20, cv = 5)\n",
    "#search = GridSearchCV(pipe, param_grid, n_jobs=2)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print outcome Grid Search\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "best_params = search.best_params_\n",
    "print(best_params) \n",
    "\n",
    "pipe_after_grid = Pipeline([('scaler', scaler), ('pca', PCA((best_params['pca__n_components']))), ('rf', rf)])\n",
    "\n",
    "# Fit pipe_after_grid on data\n",
    "bst = pipe_after_grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#TEST PERFORMANCE\n",
    "y_pred = bst.predict(X_val)\n",
    "y_val = (np.array(y_val))\n",
    "\n",
    "print(bst.score(X_val, y_val))\n",
    "print(recall_score(y_val, y_pred))\n",
    "print(precision_score(y_val, y_pred))\n",
    "print(roc_auc_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline LDA + RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scaler\n",
    "2. Feature extraction: LDA\n",
    "3. Classifier: RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7596899224806202\n",
      "0.7564102564102564\n",
      "0.8309859154929577\n",
      "0.7605580693815988\n"
     ]
    }
   ],
   "source": [
    "# Define steps in pipeline\n",
    "lda = LDA()\n",
    "rf = RandomForestClassifier()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create pipeline with steps: scaler, PCA, classifier\n",
    "pipe = Pipeline([('scaler', scaler), ('lda', lda), ('rf', rf)])\n",
    "\n",
    "# Define parameters for gridsearch: depending on which classifier\n",
    "# param_grid = {\n",
    "    \n",
    "# }\n",
    "# # Perform Grid Search on pipe\n",
    "# search = RandomizedSearchCV(pipe, param_grid, n_iter = 20, cv = 5,\n",
    "# scoring = 'roc_auc')\n",
    "# search.fit(X_train, y_train)\n",
    "\n",
    "# # Print outcome Grid Search\n",
    "# print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "# best_params = search.best_params_\n",
    "# print(best_params) \n",
    "\n",
    "# pipe_after_grid = Pipeline([('scaler', scaler), ('lda', lda), ('svc', svc)])\n",
    "\n",
    "# Fit pipe_after_grid on data\n",
    "bst = pipe.fit(X_train, y_train)\n",
    "\n",
    "#TEST PERFORMANCE\n",
    "y_pred = bst.predict(X_val)\n",
    "y_val = (np.array(y_val))\n",
    "\n",
    "print(bst.score(X_val, y_val))\n",
    "print(recall_score(y_val, y_pred))\n",
    "print(precision_score(y_val, y_pred))\n",
    "print(roc_auc_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline kernel-PCA + RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scaler\n",
    "2. Feature extraction: kernel-PCA\n",
    "3. Classifier: RF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.809):\n",
      "{'kpca__n_components': 45, 'kpca__kernel': 'linear'}\n",
      "<bound method BaseEstimator._get_param_names of <class 'sklearn.model_selection._search.RandomizedSearchCV'>>\n",
      "0.8294573643410853\n",
      "0.8974358974358975\n",
      "0.8333333333333334\n",
      "0.8114630467571644\n"
     ]
    }
   ],
   "source": [
    "# Define steps in pipeline\n",
    "kpca = KernelPCA()\n",
    "rf = RandomForestClassifier()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create pipeline with steps: scaler, PCA, classifier\n",
    "pipe = Pipeline([('scaler', scaler), ('kpca', kpca), ('rf', rf)])\n",
    "\n",
    "# Define parameters for gridsearch: depending on which classifier\n",
    "param_grid = {\n",
    "    \"kpca__n_components\": [5, 15, 30, 45, 60],\n",
    "    \"kpca__kernel\": ['linear', 'poly', 'rbf', 'sigmoid', 'cosine'],\n",
    "}\n",
    "# Perform Grid Search on pipe\n",
    "search = RandomizedSearchCV(pipe, param_grid, n_iter = 20, cv = 5)\n",
    "#scoring = 'roc_auc')\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print outcome Grid Search\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "best_params = search.best_params_\n",
    "print(best_params) \n",
    "print(search._get_param_names)\n",
    "pipe_after_grid = Pipeline([('scaler', scaler), ('kpca', KernelPCA((best_params['kpca__n_components']))), ('rf', rf)])\n",
    "\n",
    "# Fit pipe_after_grid on data\n",
    "bst = pipe_after_grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#TEST PERFORMANCE\n",
    "y_pred = bst.predict(X_val)\n",
    "y_val = (np.array(y_val))\n",
    "\n",
    "print(bst.score(X_val, y_val))\n",
    "print(recall_score(y_val, y_pred))\n",
    "print(precision_score(y_val, y_pred))\n",
    "print(roc_auc_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "source": [
    "# Pipeline with Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline PCA + NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scaler\n",
    "2. Feature extraction: PCA\n",
    "3. Classifier: NB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.805):\n",
      "{'pca__n_components': 5}\n",
      "0.751937984496124\n",
      "0.8717948717948718\n",
      "0.7555555555555555\n",
      "0.720211161387632\n"
     ]
    }
   ],
   "source": [
    "# Define steps in pipeline\n",
    "pca = PCA()\n",
    "gnb = GaussianNB()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create pipeline with steps: scaler, PCA, classifier\n",
    "pipe = Pipeline([('scaler', scaler), ('pca', pca), ('gnb', gnb)])\n",
    "\n",
    "# Define parameters for gridsearch: depending on which classifier\n",
    "param_grid = {\n",
    "    \"pca__n_components\": [5, 15, 30, 45, 60],\n",
    "    \n",
    "}\n",
    "# Perform Grid Search on pipe\n",
    "search = RandomizedSearchCV(pipe, param_grid, n_iter = 20, cv = 5)\n",
    "#search = GridSearchCV(pipe, param_grid, n_jobs=2)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print outcome Grid Search\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "best_params = search.best_params_\n",
    "print(best_params) \n",
    "\n",
    "pipe_after_grid = Pipeline([('scaler', scaler), ('pca', PCA((best_params['pca__n_components']))), ('gnb', gnb)])\n",
    "\n",
    "# Fit pipe_after_grid on data\n",
    "bst = pipe_after_grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#TEST PERFORMANCE\n",
    "y_pred = bst.predict(X_val)\n",
    "y_val = (np.array(y_val))\n",
    "\n",
    "print(bst.score(X_val, y_val))\n",
    "print(recall_score(y_val, y_pred))\n",
    "print(precision_score(y_val, y_pred))\n",
    "print(roc_auc_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline LDA + NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scaler\n",
    "2. Feature extraction: LDA\n",
    "3. Classifier: NB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751937984496124\n",
      "0.7692307692307693\n",
      "0.8108108108108109\n",
      "0.7473604826546003\n"
     ]
    }
   ],
   "source": [
    "# Define steps in pipeline\n",
    "lda = LDA()\n",
    "gnb = GaussianNB()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create pipeline with steps: scaler, PCA, classifier\n",
    "pipe = Pipeline([('scaler', scaler), ('lda', lda), ('gnb', gnb)])\n",
    "\n",
    "# Define parameters for gridsearch: depending on which classifier\n",
    "# param_grid = {\n",
    "    \n",
    "# }\n",
    "# # Perform Grid Search on pipe\n",
    "# search = RandomizedSearchCV(pipe, param_grid, n_iter = 20, cv = 5,\n",
    "# scoring = 'roc_auc')\n",
    "# search.fit(X_train, y_train)\n",
    "\n",
    "# # Print outcome Grid Search\n",
    "# print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "# best_params = search.best_params_\n",
    "# print(best_params) \n",
    "\n",
    "# pipe_after_grid = Pipeline([('scaler', scaler), ('lda', lda), ('svc', svc)])\n",
    "\n",
    "# Fit pipe_after_grid on data\n",
    "bst = pipe.fit(X_train, y_train)\n",
    "\n",
    "#TEST PERFORMANCE\n",
    "y_pred = bst.predict(X_val)\n",
    "y_val = (np.array(y_val))\n",
    "\n",
    "print(bst.score(X_val, y_val))\n",
    "print(recall_score(y_val, y_pred))\n",
    "print(precision_score(y_val, y_pred))\n",
    "print(roc_auc_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline kernel-PCA + NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scaler\n",
    "2. Feature extraction: kernel-PCA\n",
    "3. Classifier: NB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.832):\n",
      "{'kpca__n_components': 45, 'kpca__kernel': 'cosine'}\n",
      "<bound method BaseEstimator._get_param_names of <class 'sklearn.model_selection._search.RandomizedSearchCV'>>\n",
      "0.7441860465116279\n",
      "0.8846153846153846\n",
      "0.7419354838709677\n",
      "0.7070135746606334\n"
     ]
    }
   ],
   "source": [
    "# Define steps in pipeline\n",
    "kpca = KernelPCA()\n",
    "gnb = GaussianNB()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create pipeline with steps: scaler, PCA, classifier\n",
    "pipe = Pipeline([('scaler', scaler), ('kpca', kpca), ('gnb', gnb)])\n",
    "\n",
    "# Define parameters for gridsearch: depending on which classifier\n",
    "param_grid = {\n",
    "    \"kpca__n_components\": [5, 15, 30, 45, 60],\n",
    "    \"kpca__kernel\": ['linear', 'poly', 'rbf', 'sigmoid', 'cosine'],\n",
    "}\n",
    "# Perform Grid Search on pipe\n",
    "search = RandomizedSearchCV(pipe, param_grid, n_iter = 20, cv = 5)\n",
    "#scoring = 'roc_auc')\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print outcome Grid Search\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "best_params = search.best_params_\n",
    "print(best_params) \n",
    "print(search._get_param_names)\n",
    "pipe_after_grid = Pipeline([('scaler', scaler), ('kpca', KernelPCA((best_params['kpca__n_components']))), ('gnb', gnb)])\n",
    "\n",
    "# Fit pipe_after_grid on data\n",
    "bst = pipe_after_grid.fit(X_train, y_train)\n",
    "\n",
    "#TEST PERFORMANCE\n",
    "y_pred = bst.predict(X_val)\n",
    "y_val = (np.array(y_val))\n",
    "\n",
    "print(bst.score(X_val, y_val))\n",
    "print(recall_score(y_val, y_pred))\n",
    "print(precision_score(y_val, y_pred))\n",
    "print(roc_auc_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline PCA + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scaler\n",
    "2. Feature extraction: PCA\n",
    "3. Classifier: SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.818):\n",
      "{'pca__n_components': 30}\n",
      "0.8062015503875969\n",
      "0.8717948717948718\n",
      "0.8192771084337349\n",
      "0.7888386123680241\n"
     ]
    }
   ],
   "source": [
    "# Define steps in pipeline\n",
    "pca = PCA()\n",
    "svc = SVC()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create pipeline with steps: scaler, PCA, classifier\n",
    "pipe = Pipeline([('scaler', scaler), ('pca', pca), ('svc', svc)])\n",
    "\n",
    "# Define parameters for gridsearch: depending on which classifier\n",
    "param_grid = {\n",
    "    \"pca__n_components\": [5, 15, 30, 45, 60],\n",
    "    \n",
    "}\n",
    "# Perform Grid Search on pipe\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=2)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print outcome Grid Search\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "best_params = search.best_params_\n",
    "print(best_params) \n",
    "\n",
    "pipe_after_grid = Pipeline([('scaler', scaler), ('pca', PCA((best_params['pca__n_components']))), ('svc', svc)])\n",
    "\n",
    "# Fit pipe_after_grid on data\n",
    "bst = pipe_after_grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bst.predict(X_val)\n",
    "y_val = (np.array(y_val))\n",
    "\n",
    "print(bst.score(X_val, y_val))\n",
    "print(recall_score(y_val, y_pred))\n",
    "print(precision_score(y_val, y_pred))\n",
    "print(roc_auc_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline LDA + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scaler\n",
    "2. Feature extraction: LDA\n",
    "3. Classifier: SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751937984496124\n",
      "0.7692307692307693\n",
      "0.8108108108108109\n",
      "0.7473604826546003\n"
     ]
    }
   ],
   "source": [
    "# Define steps in pipeline\n",
    "lda = LDA()\n",
    "svc = SVC()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create pipeline with steps: scaler, PCA, classifier\n",
    "pipe = Pipeline([('scaler', scaler), ('lda', lda), ('svc', svc)])\n",
    "\n",
    "# Define parameters for gridsearch: depending on which classifier\n",
    "# param_grid = {\n",
    "    \n",
    "# }\n",
    "# # Perform Grid Search on pipe\n",
    "# search = RandomizedSearchCV(pipe, param_grid, n_iter = 20, cv = 5,\n",
    "# scoring = 'roc_auc')\n",
    "# search.fit(X_train, y_train)\n",
    "\n",
    "# # Print outcome Grid Search\n",
    "# print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "# best_params = search.best_params_\n",
    "# print(best_params) \n",
    "\n",
    "# pipe_after_grid = Pipeline([('scaler', scaler), ('lda', lda), ('svc', svc)])\n",
    "\n",
    "# Fit pipe_after_grid on data\n",
    "bst = pipe.fit(X_train, y_train)\n",
    "\n",
    "#TEST PERFORMANCE\n",
    "y_pred = bst.predict(X_val)\n",
    "y_val = (np.array(y_val))\n",
    "\n",
    "print(bst.score(X_val, y_val))\n",
    "print(recall_score(y_val, y_pred))\n",
    "print(precision_score(y_val, y_pred))\n",
    "print(roc_auc_score(y_val, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
