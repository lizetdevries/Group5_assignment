{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "source": [
    "# TM10007 Assignment template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "CiDn2Sk-VWqE",
    "outputId": "64224cd2-6054-4b04-a3f6-af8290400dfc"
   },
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git\n",
    "#!pip install sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data module\n",
    "from adni.load_data import load_data\n",
    "# Import needed modules\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score #kan elke zijn die we willen gebruiken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and cleaning\n",
    "\n",
    "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NE_fTbKGe5z"
   },
   "outputs": [],
   "source": [
    "# Data loading \n",
    "data = load_data()\n",
    "print(f'The number of samples: {len(data.index)}')\n",
    "print(f'The number of columns: {len(data.columns)}')\n",
    "df= pd.DataFrame(data)\n",
    "\n",
    "# Reset index, add patient ID's as column\n",
    "df.reset_index(inplace=True)\n",
    "df = df.rename(columns = {'index':'ID'})\n",
    "\n",
    "# set seed\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check wheter there is missing data (NaN)\n",
    "df.notnull().values.any() # Geen missing data\n",
    "\n",
    "# Als SD 0 dan feature weggooien\n",
    "df_new = df.drop(df.std()[df.std() == 0].index.values, axis = 1)\n",
    "\n",
    "print(f'The number of samples after cleaning + std: {len(df_new.index)}')\n",
    "print(f'The number of columns after cleaning + std: {len(df_new.columns)}')\n",
    "\n",
    "# Count number of duplicated patiient ID's\n",
    "df.index.duplicated().sum() # ID's are indices in df\n",
    "X = df.drop('ID', axis=1) # Drop patient ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split in test, train and validation set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in test-set & train/validation-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test / Train split: stratified op label --> nagaan of we dit ook willen\n",
    "y = df['label'] # Define label y (output)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.25, stratify=X['label'])\n",
    "\n",
    "# Test of het gelukt is \n",
    "# print(len(X_train))\n",
    "# print(len(X_test))\n",
    "# print(sum(X_test['label']=='AD'))\n",
    "# print(sum(X_train['label']=='AD'))\n",
    "\n",
    "# Drop labels and drop patient ID\n",
    "X_train = X_train.drop('label', axis=1)\n",
    "X_test = X_test.drop('label', axis=1)\n",
    "X = X.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scaler\n",
    "2. PCA\n",
    "3. Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define steps in pipeline\n",
    "scaler = StandardScaler()\n",
    "pca = PCA()\n",
    "logistic = LogisticRegression(max_iter=10000, tol=0.1)\n",
    "\n",
    "# Create pipeline with steps: scaler, PCA, classifier\n",
    "pipe = Pipeline([('scaler', scaler), ('pca', pca), ('logistic', logistic)])\n",
    "\n",
    "# Define parameters for gridsearch: depending on which classifier\n",
    "param_grid = {\n",
    "    \"pca__n_components\": [5, 15, 30, 45, 60],\n",
    "    \"logistic__C\": np.logspace(-4, 4, 4),\n",
    "}\n",
    "# Perform Grid Search on pipe\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=2)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print outcome Grid Search\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "\n",
    "best_params = search.best_params_\n",
    "# Meer params als input voor LR: dictionary voor maken\n",
    "\n",
    "pipe_after_grid = Pipeline([('scaler', scaler), ('pca', PCA((best_params['pca__n_components']))), ('logistic', LogisticRegression((best_params['logistic__C'])))])\n",
    "\n",
    "# Fit pca on data\n",
    "#pca.fit(X_train)\n",
    "bst = pipe_after_grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
